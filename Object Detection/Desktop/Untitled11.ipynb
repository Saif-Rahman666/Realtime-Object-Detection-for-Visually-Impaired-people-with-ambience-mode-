{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "438a8f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    }
   ],
   "source": [
    "######## Webcam Object Detection Using Tensorflow-trained Classifier #########\n",
    "#\n",
    "# Author: Evan Juras\n",
    "# Date: 10/27/19\n",
    "# Description: \n",
    "# This program uses a TensorFlow Lite model to perform object detection on a live webcam\n",
    "# feed. It draws boxes and scores around the objects of interest in each frame from the\n",
    "# webcam. To improve FPS, the webcam object runs in a separate thread from the main program.\n",
    "# This script will work with either a Picamera or regular USB webcam.\n",
    "#\n",
    "# This code is based off the TensorFlow Lite image classification example at:\n",
    "# https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/python/label_image.py\n",
    "#\n",
    "# I added my own method of drawing boxes and labels using OpenCV.\n",
    "\n",
    "# Import packages\n",
    "import os\n",
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "from threading import Thread\n",
    "import importlib.util\n",
    "\n",
    "# Define VideoStream class to handle streaming of video from webcam in separate processing thread\n",
    "# Source - Adrian Rosebrock, PyImageSearch: https://www.pyimagesearch.com/2015/12/28/increasing-raspberry-pi-fps-with-python-and-opencv/\n",
    "class VideoStream:\n",
    "    \"\"\"Camera object that controls video streaming from the Picamera\"\"\"\n",
    "    def __init__(self,resolution=(640,480),framerate=30):\n",
    "        # Initialize the PiCamera and the camera image stream\n",
    "        self.stream = cv2.VideoCapture(0)\n",
    "        ret = self.stream.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))\n",
    "        ret = self.stream.set(3,resolution[0])\n",
    "        ret = self.stream.set(4,resolution[1])\n",
    "            \n",
    "        # Read first frame from the stream\n",
    "        (self.grabbed, self.frame) = self.stream.read()\n",
    "\n",
    "\t# Variable to control when the camera is stopped\n",
    "        self.stopped = False\n",
    "\n",
    "    def start(self):\n",
    "\t# Start the thread that reads frames from the video stream\n",
    "        Thread(target=self.update,args=()).start()\n",
    "        return self\n",
    "\n",
    "    def update(self):\n",
    "        # Keep looping indefinitely until the thread is stopped\n",
    "        while True:\n",
    "            # If the camera is stopped, stop the thread\n",
    "            if self.stopped:\n",
    "                # Close camera resources\n",
    "                self.stream.release()\n",
    "                return\n",
    "\n",
    "            # Otherwise, grab the next frame from the stream\n",
    "            (self.grabbed, self.frame) = self.stream.read()\n",
    "\n",
    "    def read(self):\n",
    "\t# Return the most recent frame\n",
    "        return self.frame\n",
    "\n",
    "    def stop(self):\n",
    "\t# Indicate that the camera and thread should be stopped\n",
    "        self.stopped = True\n",
    "\n",
    "\n",
    "\n",
    "MODEL_NAME = 'C:/Users/Raihan/.keras/datasets/centernet_mobilenetv2_fpn_od/'\n",
    "GRAPH_NAME = 'model.tflite'\n",
    "LABELMAP_NAME = 'label_map.txt'\n",
    "resolution = '1280x720'\n",
    "min_conf_threshold = float(0.1)\n",
    "resW, resH = resolution.split('x')\n",
    "imW, imH = int(resW), int(resH)\n",
    "\n",
    "# Import TensorFlow libraries\n",
    "# If tflite_runtime is installed, import interpreter from tflite_runtime, else import from regular tensorflow\n",
    "# If using Coral Edge TPU, import the load_delegate library\n",
    "pkg = importlib.util.find_spec('tflite_runtime')\n",
    "if pkg:\n",
    "    from tflite_runtime.interpreter import Interpreter\n",
    "    from tensorflow.lite.python.interpreter import Interpreter  \n",
    "\n",
    "# Get path to current working directory\n",
    "CWD_PATH = os.getcwd()\n",
    "\n",
    "# Path to .tflite file, which contains the model that is used for object detection\n",
    "PATH_TO_CKPT = os.path.join(CWD_PATH,MODEL_NAME,GRAPH_NAME)\n",
    "\n",
    "# Path to label map file\n",
    "PATH_TO_LABELS = os.path.join(CWD_PATH,MODEL_NAME,LABELMAP_NAME)\n",
    "\n",
    "# Load the label map\n",
    "with open(PATH_TO_LABELS, 'r') as f:\n",
    "    labels = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "# Have to do a weird fix for label map if using the COCO \"starter model\" from\n",
    "# https://www.tensorflow.org/lite/models/object_detection/overview\n",
    "# First label is '???', which has to be removed.\n",
    "if labels[0] == '???':\n",
    "    del(labels[0])\n",
    "\n",
    "# Load the Tensorflow Lite model.\n",
    "# If using Edge TPU, use special load_delegate argument\n",
    "\n",
    "interpreter = Interpreter(model_path=PATH_TO_CKPT)\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get model details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "height = input_details[0]['shape'][1]\n",
    "width = input_details[0]['shape'][2]\n",
    "print(height)\n",
    "floating_model = (input_details[0]['dtype'] == np.float32)\n",
    "\n",
    "input_mean = 127.5\n",
    "input_std = 127.5\n",
    "\n",
    "# Initialize frame rate calculation\n",
    "frame_rate_calc = 1\n",
    "freq = cv2.getTickFrequency()\n",
    "\n",
    "# Initialize video stream\n",
    "videostream = VideoStream(resolution=(imW,imH),framerate=30).start()\n",
    "time.sleep(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ce28a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03650567 0.02199644 0.0171172  0.01706529 0.01687947 0.01687387\n",
      " 0.01653931 0.0159564  0.01537171 0.01491487]\n",
      "[0.04000932 0.02294466 0.01847777 0.01846075 0.01775983 0.01649448\n",
      " 0.01587373 0.01537842 0.014869   0.01349887]\n",
      "[0.04014269 0.02346027 0.01872724 0.01830196 0.01784551 0.01758206\n",
      " 0.01684678 0.01582697 0.01524323 0.01507011]\n",
      "[0.04312497 0.02472317 0.01975015 0.01948211 0.01927167 0.01864597\n",
      " 0.01710355 0.01625812 0.01527694 0.01492503]\n",
      "[0.03676257 0.02216771 0.01759839 0.01747307 0.01696342 0.01687816\n",
      " 0.01622385 0.01608354 0.01553556 0.01528966]\n",
      "[0.0378193  0.02261809 0.01845515 0.018231   0.01773503 0.01631695\n",
      " 0.01566619 0.01521754 0.01521289 0.01515314]\n",
      "[0.0392054  0.02322781 0.01870474 0.01780704 0.01758373 0.01695341\n",
      " 0.01511049 0.01481098 0.01411569 0.01361912]\n",
      "[0.03484979 0.02254787 0.01788038 0.01786315 0.01750645 0.01537296\n",
      " 0.01486504 0.01483929 0.01480052 0.01466686]\n",
      "[0.03704792 0.02307412 0.01882708 0.01799294 0.01782465 0.01610863\n",
      " 0.01598933 0.01585671 0.01516378 0.01457229]\n",
      "[0.03791162 0.02323765 0.01952252 0.01800868 0.0174728  0.01736644\n",
      " 0.01714101 0.01684356 0.01584423 0.01527911]\n",
      "[0.03680894 0.02258003 0.01855502 0.01824799 0.01747435 0.01610801\n",
      " 0.01608291 0.01596853 0.01519716 0.01421919]\n",
      "[0.03689852 0.02242669 0.01856425 0.01792827 0.0172753  0.01599237\n",
      " 0.01580963 0.01563528 0.01550293 0.01543197]\n",
      "[0.03825527 0.02244586 0.01786345 0.01717409 0.01620632 0.01597172\n",
      " 0.0157178  0.01512599 0.01491833 0.01440465]\n",
      "[0.03882134 0.0227654  0.01852375 0.01812851 0.01753262 0.01681197\n",
      " 0.0162507  0.01617777 0.01614821 0.0161193 ]\n",
      "[0.03687739 0.02106446 0.02073595 0.01996863 0.01984182 0.01945275\n",
      " 0.01662922 0.01640642 0.01537216 0.01365125]\n",
      "[0.03967008 0.02348211 0.02055344 0.02032465 0.01856455 0.01729268\n",
      " 0.01698548 0.01445389 0.0136553  0.01236054]\n",
      "[0.03171477 0.02019083 0.01979786 0.01909643 0.01773962 0.01674196\n",
      " 0.01671591 0.01660275 0.01461032 0.01435509]\n",
      "[0.03799757 0.0220508  0.01817593 0.01774141 0.01673055 0.01672456\n",
      " 0.01610881 0.01580027 0.01466829 0.01324093]\n",
      "[0.02722067 0.02115333 0.01947865 0.01868069 0.01831463 0.01693296\n",
      " 0.01603407 0.01469156 0.014294   0.01347807]\n",
      "[0.02521399 0.02207386 0.01984829 0.01725066 0.01604775 0.01599261\n",
      " 0.01562411 0.01452103 0.01387876 0.01272008]\n",
      "[0.03325954 0.0214535  0.02096465 0.01969099 0.01731941 0.01710966\n",
      " 0.0168165  0.0165247  0.015223   0.01342893]\n",
      "[0.03030404 0.02180359 0.02094045 0.02013129 0.01972491 0.0162105\n",
      " 0.0160968  0.01317194 0.01264304 0.01197314]\n",
      "[0.02668226 0.02127603 0.01948822 0.01877576 0.01607788 0.01491156\n",
      " 0.01439542 0.01426482 0.01318583 0.01283264]\n",
      "[0.02554676 0.02180114 0.02034599 0.01842371 0.01635745 0.01608273\n",
      " 0.01465458 0.01452804 0.01333863 0.01237458]\n",
      "[0.0273934  0.02324963 0.02009636 0.01888609 0.01759675 0.01563567\n",
      " 0.01538676 0.01372382 0.01268947 0.01261646]\n",
      "[0.03685835 0.02278441 0.02069744 0.01953363 0.01950496 0.01930547\n",
      " 0.01777253 0.01730818 0.0165337  0.01567549]\n",
      "[0.04115179 0.02274108 0.01866466 0.01855639 0.01841196 0.01806897\n",
      " 0.01488614 0.0121178  0.01207301 0.01192471]\n",
      "[0.03519505 0.02159986 0.01895621 0.0185762  0.01841173 0.01595336\n",
      " 0.01379126 0.01371539 0.01345405 0.01309091]\n",
      "[0.03410363 0.02034029 0.01809028 0.01762593 0.01761732 0.0173488\n",
      " 0.01639974 0.01542759 0.01469749 0.01408961]\n",
      "[0.03545514 0.02056468 0.01722851 0.01672921 0.01650977 0.01630172\n",
      " 0.01568335 0.01555112 0.01462489 0.01398075]\n",
      "[0.03652897 0.02127159 0.01705432 0.01702231 0.01685333 0.01664779\n",
      " 0.01622522 0.01549581 0.01532653 0.01532301]\n",
      "[0.03758386 0.02148506 0.01788035 0.01751378 0.01720589 0.01566955\n",
      " 0.01560059 0.01559442 0.01554611 0.01316249]\n",
      "[0.03905874 0.02251792 0.0203352  0.01979446 0.01817894 0.01799396\n",
      " 0.01618364 0.0161669  0.01471153 0.01344153]\n"
     ]
    }
   ],
   "source": [
    "#for frame1 in camera.capture_continuous(rawCapture, format=\"bgr\",use_video_port=True):\n",
    "while True:\n",
    "\n",
    "    # Start timer (for calculating frame rate)\n",
    "    t1 = cv2.getTickCount()\n",
    "\n",
    "    # Grab frame from video stream\n",
    "    frame1 = videostream.read()\n",
    "\n",
    "    # Acquire frame and resize to expected shape [1xHxWx3]\n",
    "    frame = frame1.copy()\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_resized = cv2.resize(frame_rgb, (width, height))\n",
    "    input_data = np.expand_dims(frame_resized, axis=0)\n",
    "\n",
    "    # Normalize pixel values if using a floating model (i.e. if model is non-quantized)\n",
    "    if floating_model:\n",
    "        input_data = (np.float32(input_data) - input_mean) / input_std\n",
    "        \n",
    "    # Perform the actual detection by running the model with the image as input\n",
    "    interpreter.set_tensor(input_details[0]['index'],input_data)\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # Retrieve detection results\n",
    "    boxes = interpreter.get_tensor(output_details[0]['index'])[0] # Bounding box coordinates of detected objects\n",
    "    classes = interpreter.get_tensor(output_details[1]['index'])[0] # Class index of detected objects\n",
    "    scores = interpreter.get_tensor(output_details[2]['index'])[0] # Confidence of detected objects\n",
    "    #num = interpreter.get_tensor(output_details[3]['index'])[0]  # Total number of detected objects (inaccurate and not needed)\n",
    "    print(scores)\n",
    "    # Loop over all detections and draw detection box if confidence is above minimum threshold\n",
    "    for i in range(len(scores)):\n",
    "        if ((scores[i] > min_conf_threshold) and (scores[i] <= 1.0)):\n",
    "            \n",
    "            # Get bounding box coordinates and draw box\n",
    "            # Interpreter can return coordinates that are outside of image dimensions, need to force them to be within image using max() and min()\n",
    "            ymin = int(max(1,(boxes[i][0] * imH)))\n",
    "            xmin = int(max(1,(boxes[i][1] * imW)))\n",
    "            ymax = int(min(imH,(boxes[i][2] * imH)))\n",
    "            xmax = int(min(imW,(boxes[i][3] * imW)))\n",
    "            \n",
    "            cv2.rectangle(frame, (xmin,ymin), (xmax,ymax), (10, 255, 0), 2)\n",
    "\n",
    "            # Draw label\n",
    "            object_name = labels[int(classes[i])] # Look up object name from \"labels\" array using class index\n",
    "            label = '%s: %d%%' % (object_name, int(scores[i]*100)) # Example: 'person: 72%'\n",
    "            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2) # Get font size\n",
    "            label_ymin = max(ymin, labelSize[1] + 10) # Make sure not to draw label too close to top of window\n",
    "            cv2.rectangle(frame, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED) # Draw white box to put label text in\n",
    "            cv2.putText(frame, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2) # Draw label text\n",
    "\n",
    "    # Draw framerate in corner of frame\n",
    "    cv2.putText(frame,'FPS: {0:.2f}'.format(frame_rate_calc),(30,50),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,0),2,cv2.LINE_AA)\n",
    "\n",
    "    # All the results have been drawn on the frame, so it's time to display it.\n",
    "    cv2.imshow('Object detector', frame)\n",
    "\n",
    "    # Calculate framerate\n",
    "    t2 = cv2.getTickCount()\n",
    "    time1 = (t2-t1)/freq\n",
    "    frame_rate_calc= 1/time1\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "cv2.destroyAllWindows()\n",
    "videostream.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8faf7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
